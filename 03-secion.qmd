# Etapa 2 <br> Manipulación de tus datos

```{r}
#| echo: false
#| message: false
library(readxl)
library(tidyverse)
library(janitor)
library(here)
library(gtsummary)
library(padr)
library(countdown)
library(emo)
```

## ¿Dónde estamos ahora?

- Hemos realizado la DEV (Exploración y Validación de Datos) - con más validación por hacer. La validación de datos es un proceso continuo, hasta llegar al bloqueo de datos.
- Discutimos la importancia de prevenir errores de datos en la fuente.

## ¿Dónde estamos ahora?

\
- Realizamos la limpieza de la Etapa 1: limpiamos los nombres de las variables, eliminamos columnas/filas vacías, corregimos los tipos/clases de variables (caracteres a numéricos, recodificación de factores, Problemaas con fechas), abordamos los valores faltantes y las violaciones de los principios de datos ordenados (separación).

- Si bien la Etapa 1 es necesaria en casi todos los proyectos, a menudo es necesario realizar la limpieza de datos de la Etapa 2, pero no en todos los proyectos.

## Limpieza de datos de la Etapa 2

- Cubriremos los siguientes temas:
  - Reestructuración de datos en formato largo - ancho.
  - Ampliación o relleno de datos longitudinales.
  - Unión de múltiples conjuntos de datos.

## Reestructuración de datos en formato largo - ancho

Formato Ancho

```{r, echo=FALSE}
wide <- readxl::read_excel(here("data/messy_uc.xlsx"), sheet = 3, skip = 6) |>
  janitor::clean_names() |>
  janitor::remove_empty(which = c("rows", "cols")) |> 
  select(pat_id, treatment, ends_with("mes"), ends_with("bss"), ends_with("emo")) |> 
  mutate(across(3:8, as.numeric)) 

head(wide)
```

Formato Largo 

```{r, echo=FALSE}
wide |> 
  pivot_longer(cols = 3:8,
               names_to = "measure",
               values_to = "score") |> 
  head(9)
```


## La Unidad de Análisis - Formato ancho

- Es posible que deseemos realizar un análisis por paciente, ya que cada paciente puede (o no) tener el Resultadoado. Si tenemos múltiples observaciones o puntos de datos en cada paciente,esto se puede almacenar en formato ancho, con una fila por paciente.


```{r,  echo=FALSE, warning=FALSE, message=FALSE}
wide <- readxl::read_excel(here("data/messy_uc.xlsx"), sheet = 3, skip = 6) |>
  janitor::clean_names() |>
  janitor::remove_empty(which = c("rows", "cols")) |>
  select(pat_id, treatment, ends_with("mes"), ends_with("bss"), ends_with("emo")) |>
  mutate(across(3:8, as.numeric))

head(wide)
```

## La Unidad de Análisis - Formato largo

- A menudo nos interesa el cambio en un Resultadoado a lo largo del tiempo.
- Para que esto funcione, necesitamos una fila por cada medición del Resultadoado. Esto genera datos en formato largo, con múltiples visitas y mediciones para cada paciente.


```{r, echo=FALSE}
wide |>
  pivot_longer(cols = 3:8,
               names_to = "measure",
               values_to = "score")
```



## Decisiónes sobre la Unidad de Análisis

- La unidad de análisis generalmente depende de la `Pregunta` que hacemos.

¿Es el Paciente la Unidad de Análisis?

  - ¿El paciente falleció?
  - ¿El paciente tuvo el Resultadoado de positivo/...?
  - ¿El paciente alcanzó la remisión de la enfermedad?

¿Es la consulta la unidad de análisis?

  - ¿Mejoró los valores de ... de la Semana 0 a la Semana 8?
  - ¿Disminuyeron las afecciones, conteos .... después del tratamiento?


## Decisiónes sobre la Unidad de Análisis

  - La mayoría de las veces utilizarás datos en formato largo, y esta estructura de datos permite examinar múltiples predictores y Resultados.
  
- Dependiendo de la pregunta de análisis, es posible que desees utilizar datos en formato ancho (generalmente con Resultados dicotómicos).


## Reorganización de los datos con tidyr


::: panel-tabset
### Problemaa

-   A menudo *ingresamos* los datos por para cada una de las muestras.

-   Terminamos con datos "en formato ancho" en lugar de datos "en formato largo"

### Formato ancho

```{r,  echo=FALSE, warning=FALSE, message=FALSE}
wide <- readxl::read_excel(here("data/messy_uc.xlsx"), sheet = 3, skip = 6) |>
  janitor::clean_names() |>
  janitor::remove_empty(which = c("rows", "cols")) |>
  select(pat_id, treatment, ends_with("mes"), ends_with("bss"), ends_with("emo")) |>
  mutate(across(3:8, as.numeric))

head(wide)
```

### Formato largo

```{r, echo=FALSE}
wide |>
  pivot_longer(cols = 3:8,
               names_to = "measure",
               values_to = "score")
```
:::

## Reorganización de los datos con tidyr

-   R (y la mayoría de las funciones de R) están vectorizados para manejar datos en formato largo.
-   Una pequeña observación por fila.
-   La mayoría de los análisis en R son más fáciles de ejecutar con datos en formato largo.


```{r, echo=FALSE}
wide |>
  pivot_longer(cols = 3:8,
               names_to = "measure",
               values_to = "score")
```


## Pivoteando a un formato largo

-   Necesitamos reorganizar los datos de formato ancho a formato largo de manera regular.
-   Esto "alarga" los datos, aumentando el número de filas y disminuyendo el número de columnas.

## Pivoteando a un formato largo

-   Argumentos: `data`, `cols`, `names_to`, `values_to` y otros argumentos opcionales.
-   Detalles de la página de ayuda de tidyverse [aquí](https://tidyr.tidyverse.org/reference/pivot_longer.html).

-   `data` = tu dataframe/tibble, puedes usar el operador pipe ` |> | %>%`.

-   `cols` = columnas a reorganizar, como un vector de nombres, por número o seleccionadas con las funciones de [tidyselect](https://tidyselect.r-lib.org).

-   `names_to` = Nombre de la nueva columna o columnas a crear a partir de la información almacenada en los nombres de columna de los datos especificados por `cols`.

-   `values_to` = nombre de la columna a crear a partir de los datos almacenados en los valores de las celdas.

## Pivoteando a un formato largo

Comencemos con la versión de en formato ancho(columnas seleccionadas de `messy_uc`)

```{r, echo=FALSE, warning=FALSE, message=FALSE}
wide <- readxl::read_excel(here("data/messy_uc.xlsx"), sheet = 3, skip = 6) |>
  janitor::clean_names() |>
  janitor::remove_empty(which = c("rows", "cols")) |>
  select(pat_id, treatment, ends_with("mes"), ends_with("bss"), ends_with("emo")) |>
  mutate(across(3:8, as.numeric))

wide
```

- Ten en cuenta que hay 30 filas de observaciones, con 6 cantidades medidas para cada observación.

## Pivoteando a un formato largo

Esta es la versión larga con la que queremos terminar.

```{r, echo=FALSE}
wide |>
  pivot_longer(cols = 3:8,
               names_to = "measure",
               values_to = "score")
```

-   Ten en cuenta que ahora hay 180 filas (30\*6), con una fila por cada medida y cada observación.

## Realizando el pivot_longer()

¿Qué valores queremos para estos argumentos clave para usar `tidyr::pivot_longer`?

-   `cols` (¿qué columnas queremos pivotear?)
-   `names_to` (variable para almacenar los nombres de las columnas)
-   `values_to` (variable para almacenar los valores de cada una de las mediciones)


```{r, echo=FALSE}
wide
```

## `tidyr::pivot_longer()`

::: panel-tabset

### Problema

```{r, echo=FALSE}
wide
```

### Code

```{r, echo=TRUE, eval=FALSE}
wide |> # <1>
  pivot_longer(
    cols = "start_mes":"end_emo",
    names_to = "measure", # <2>
    values_to = "score" # <3>
  ) # <4>
```

1. comienza con datos en formato ancho y utiliza `tidyr::pivot_longer()`
2. Indica qué columnas pivotar (selección por nombre, posición, coincidencia..),
3. Indica en qué columna (entre comillas) deben ir los nombres de las variables pivoteadas
4. Indica en qué columna (entre comillas) deben ir los valores pivoteados

### Resultado

```{r, echo=FALSE, eval=TRUE}
tall <- wide |>
  pivot_longer(
    cols = "start_mes":"end_emo",
    names_to = "measure",
    values_to = "score")

tall
```

:::

## Un problema menor: Separación de medidas

::: panel-tabset

### Problema

- La columna "measure" combina un punto en el tiempo y la medición. 
- Necesita ser separada.
- Ya sabes cómo usar *separate()*
  - Argumentos
- `col`
- `sep`
- `into`

### Código

```{r, echo=TRUE, eval=FALSE}
tall |>
  separate(col = "measure",
           sep = "_",
           into = c("timept", "measure")
  )
```


### Resultado

```{r, echo=FALSE, eval=TRUE}
tall |>
  separate(col = "measure",
           sep = "_",
           into = c("timept", "measure"))
```


### `pivot_longer()`

- Puedes hacer esto *dentro de* pivot_longer con solo un argumento adicional <br>(si *lees toda la documentación de pivot_longer*)


::: columns

::: {.column width="50%"}
```{r, echo=TRUE, eval=FALSE}
wide |>
  pivot_longer(cols = 3:8,
               names_to = c("timept", "measure"),
               names_sep = "_",
               values_to = "score")

```

:::

::: {.column width="50%"}
```{r, echo=FALSE, eval=TRUE}
wide |>
  pivot_longer(cols = 3:8,
               names_to = c("timept", "measure"),
               names_sep = "_",
               values_to = "score")

```
:::

:::
:::



## Pivoteo hacia un formato ancho

::: panel-tabset

### formato largo 
::: columns

::: {.column width="50%"}

-   Los datos en formato largo son menos comunes, pero a veces son necesarios para el análisis por observación.
-   Aquí convertiremos la versión larga de nuestros datos seleccionados "messy_uc" nuevamente a una versión ancha.
-   Así es como se ven los datos en su forma larga.

:::

::: {.column width="50%"}

```{r, echo=FALSE}
tall
```
:::
:::
:::
## Pivoteo hacia un formato ancho

```{r echo=TRUE, eval=FALSE}

tall |>
  pivot_wider(
    id_cols = c(pat_id, treatment), # Variables no pivotadas
    names_from = measure, # Variable que se convertirán en nombres de columnas
    values_from = score # Variable que se convertirán en valores
  )
```

## Pivoteo hacia un formato ancho

```{r echo=FALSE, eval=TRUE}
tall |>
  pivot_wider(
    id_cols = c(pat_id, treatment),
    names_from = measure,
    values_from = score
  )
```

:::

## Datos longitudinales

::: columns
::: {.column width="60%"}

- Otro conjunto de problemas en la gestión de datos que puedes enfrentar son los datos recopilados a lo largo del tiempo, cuando ocurre una de estas dos cosas:

  - Quieres analizar datos por día, mes o año, y los datos en están recopilados y registrados por `segundo`.
  - Te das cuenta de que faltan algunas observaciones  y necesitas completar estas fechas como faltantes, pero realmente no quieres hacerlo manualmente.
- El paquete {padr} puede ayudar con estos problemas.

:::
  ::: {.column width="40%"}
![Datos longitudinales](images/long_data.png)
:::
:::


## Gestinando las fechas y horas con padr

::: columns
::: {.column width="55%"}
```{r, echo=FALSE}
library(padr)
library(tidyverse)
emergency <- padr::emergency
head(emergency) |>
  select(title, time_stamp)
```
:::

::: {.column width="2%"}
:::

::: {.column width="43%"}

-   El conjunto de datos **emergency** en el paquete {padr} contiene > 120K llamadas de emergencia del condado de Montgomery, PA durante un período de ~ 11 meses.
-   Cada llamada tiene un título y una marca de tiempo.

:::
:::

## Organizando el tiempo a un nivel utilizable

::: panel-tabset
### Inicio

- La función `thicken` agrega una columna a un data.frame que tiene un intervalo más amplio que la variable original.
- Los intervalos para {padr} son año, trimestre, mes, semana, día, hora, minuto y segundo.
- La variable `time_stamp` tiene un intervalo de segundos.
- Podemos aumentar el intervalo de los datos al intervalo de tiempo que necesitamos.
- Luego podemos contar eventos por una unidad de tiempo utilizable.

### Data original

```{r}
#| echo: true
#| eval: true
emergency |>
  head()
```

###  Organizando por mes
-   Vamos a agrupar por mes

```{r}
#| echo: true
#| eval: true
emergency |>
  thicken('month') |>
  head() |>
  select(-lat, -lng, -zip)
```

### Organizando por semana
-   Vamos a agrupar por semana

```{r}
#| echo: true
#| eval: true
emergency |>
  thicken('week') |>
  head() |>
  select(-lat, -lng, -zip)
```

:::


## Agrupando para un gráfico mensual
::: panel-tabset

### Objetivo

-   La función `thicken` agrega una columna a un data.frame que tiene un intervalo mayor que la variable original.
-   La variable `time_stamp` tiene un intervalo de segundos.
-   Queremos agrupar estos datos (con marca de tiempo) a nivel mensual, luego seleccionar y contar las sobredosis (overdose).
-   Esto nos permitirá configurar el gráfico mensual de sobredosis que deseamos.

### Código

-   Agrupar a nivel mensual.
-   Luego contaremos las sobredosis por mes.

```{r}
#| echo: true
#| eval: false
emergency |>
  thicken('month') |>
  group_by(time_stamp_month) |>
  summarize(overdoses = sum(str_detect(title, "OVERDOSE"))) |>
  select(time_stamp_month, overdoses)
```

### Resultado

```{r}
#| echo: false
#| eval: true
by_month <- emergency |>
  thicken('month') |>
  group_by(time_stamp_month) |>
  summarize(overdoses = sum(str_detect(title, "OVERDOSE"))) |>
  select(time_stamp_month, overdoses)

by_month
```

### Gráfico mensual
```{r}
#| echo: false
#| eval: true
#| fig-height: 4

by_month |>
  ggplot(aes(x = time_stamp_month,
             y = overdoses)) +
  geom_point(size = 3, color = "red") +
  geom_line() +
  labs(y = "Sobredosis por mes",
       x = "Mes",
       title = "Lammadas por sobredosis por mes") +
  theme_linedraw(base_size = 20) +
  ylim(0,175)
```

:::


## Rellenar fechas no observadas (fines de semana, feriados ...)

::: columns
::: {.column width="60%"}

-   La función `pad()` te permite completar intervalos faltantes.
-   Permitiendo resolver discontinuidades extrañas en los datos.

:::

::: {.column width="40%"}
```{r}
#| echo: false
fcp <- tibble::tribble(
  ~pat_id, ~date, ~fcp,
  '001', "12-01-2022", 1574,
  '001', "12-02-2022", 1323,
  '001', "12-05-2022", 673,
  '001', "12-06-2022", 314,
  '001', "12-07-2022", 168,
  '002', "11-30-2022", 1393,
  '002', "12-01-2022", 1014,
  '002', "12-02-2022", 812,
  '002', "12-05-2022", 247,
  '002', "12-06-2022", 118,
  '003', "12-02-2022", 987,
  '003', "12-05-2022", 438,
  '003', "12-06-2022", 312,
  '003', "12-05-2022", 194,
  '003', "12-06-2022", 101
) |> mutate(date = lubridate::mdy(date))

fcp |>  head(14)
```
:::
:::

## Completando fechas sin observaciones

::: panel-tabset
### Problema
-   Podemos completar los días sin observaciones con la función `pad()`.

### Codigo

```{r}
#| echo: true
#| eval: false
fcp |>
  pad(group = "pat_id") |> # esto agrega líneas para cada día faltante en los datos
  print(n = 12)
```

### Resultado

::: columns
::: {.column width="40%"}
```{r}
#| echo: false
#| eval: true
fcp |>
  pad(group = "pat_id") |>
  print(n = 12)
```
:::

::: {.column width="60%"}

-   Se crean nuevas observaciones en las fechas faltantes
-   Se rellenan los valores NA para los FCPs faltantes, uno para cada día y grupo (pat_id)
-   `pad()` completa los pat_ids faltantes
:::
:::
:::

## Uniendo datos

::: columns
::: {.column width="60%"}

- Otro problema en la gestión de datos que a menudo enfrentarás es que tienes dos conjuntos de datos interesantes y serían aún más interesantes si se pudieran vincular los datos de uno con los datos del otro.

:::

::: {.column width="40%"}
![Better Together: <br>Chocolate and Peanut Butter <br> (Datasets)](images/choc_pb.jpeg)
:::

:::

## Combinación de datos de diferentes fuentes

::: columns
::: {.column width="70%"}

-   A menudo recopilamos datos de diferentes fuentes que luego queremos combinar para su análisis.
-   Datos de tu Registro Médico Electrónico local.
-   Datos del CDC (Centros para el Control y la Prevención de Enfermedades).
-   Datos del censos poblacionales.
-   Los datos externos pueden ampliar la comprensión de nuestros datos.

:::

::: {.column width="30%"}
![](images/LuxoJr_Lamp.webp)
:::

:::

## Combinación de datos de diferentes fuentes

::: panel-tabset
### Problema

-   Tenemos 2 conjuntos de datos, uno de Demografía y Distrito Censal local, y otro del CDC que tiene valores del Índice de Vulnerabilidad Social (SVI) por Distrito Censal.
-   Queremos saber si el SVI del vecindario de cada paciente influye en los resultados de salud.
-   Necesitamos hacer una unión (`left_join`) de estos conjuntos de datos mediante la coincidencia en el Distrito Censal.


### Datos

  -  Cual es la variable en común  - variable de unión - variable de conexión. 

:::: columns
::: {.column width="60%"}

-  `demo`

```{r}
#| echo: false
demo <- tibble::tribble(
  ~pat_id, ~name, ~htn, ~census_tract,
  '001', "Arthur Blankenship", 0, 26161404400,
  '002', "Britney Jonas", 0, 26161405100,
  '003', "Sally Davis", 1, 26161402100,
  '004', "Al Jones", 0, 26161403200,
  '005', "Gary Hamill", 1, 26161405200,
  '006', "Ken Bartoletti", 0, 26161404500,
  '007', "Ike Gerhold", 0, 26161405600,
  '008', "Tatiana Grant", 0, 26161404300,
  '009', "Antione Delacroix", 1, 26161405500,
)

demo
```

:::

::: {.column width="40%"}

-   `cdc`

```{r}
#| echo: false
cdc <- tibble::tribble(
  ~census_tract, ~svi,
  26161404400, 0.12,
  26161405100, 0.67,
  26161402100, 0.43,
  26161403200, 0.07,
  26161405200, 0.71,
  26161404500, 0.23,
  26161405600, 0.27,
  26161404300, 0.21,
  26161405500, 0.62
)

cdc
```
:::

::::

### Codigo

-   Reemplaza los argumentos genéricos de la función `left_join()` para unir los datos demográficos (*demo*) en el lado izquierdo y agregar el índice de Vulnerabilidad Social (SVI) del conjunto de datos *cdc* en el lado derecho.


```{r, echo=TRUE, eval=FALSE}
left_join(demo, cdc, by = "census_tract")
```

### Resultado

- Ahora que se ha completado la unión, puedes hacer tu pregunta:
  -   ¿Existe una asociación entre la vulnerabilidad social y la hipertensión?


```{r, echo=FALSE, eval=TRUE}
left_join(demo, cdc, by = "census_tract")
```
:::

## Uniones avanzadas

-   Hay varios tipos de uniones avanzadas (*semi_join, anti_join, inner_join, full_join, union, intersect, setdiff*) que resultan útiles de vez en cuando.
-   Los diferentes tipos de uniones están bien explicados [aquí](http://statseducation.com/Introduction-to-R/modules/tidy%20data/joins/#:~:text=semi_join(x%2C%20y)%3A%20Return,This%20is%20a%20filtering%20join.)

## Uniones avanzadas
::: columns

::: {.column width="45%"}
- Filtra tus datos (x), manteniendo solo aquellos (y) que coinciden en ambas bases de datos.

 <div class="animations"><img alt="gif here" width="100%" height="100%" src="https://raw.githubusercontent.com/gadenbuie/tidyexplain/main/images/semi-join.gif"> </div>
:::

::: {.column width="10%"}
:::

::: {.column width="45%"}

- Filtra tus datos (x), omitiendo aquellos (y) que estan en ambas bases de datos.

 <div class="animations"><img alt="gif here" width="100%" height="100%" src="https://raw.githubusercontent.com/gadenbuie/tidyexplain/main/images/anti-join.gif"> </div>
:::

:::


## Opciones avanzadas

- Puedes usar `join_by` para más opciones de unión, incluyendo
    + desigualdad: solo hacer coincidencia si es mayor que un valor
    + fecha más cercana
    + `fecha más cercana` siempre y cuando sea _después_ de la fecha de comparación, pero dentro de los 30 días
    + solo hacer coincidencia si el intervalo/fecha `se superpone`
    + hacer coincidencia si el valor está `dentro` de un rango
- Obtén más información en [Join Specifications](https://dplyr.tidyverse.org/reference/join_by.html)





## Datos desorganizados o fragmentados

::: columns

::: {.column width="50%"}

1. Puedes encontrar a la persona que recolectó/ingresó los datos

- Si no corriges este comportamiento ahora, esto obstaculiza la adecuada gestión de datos y reproducibilidad.

- Mejora tus conocimientos sobre datos ordenados (tidy data).

- **Mejora** la gestión de datos, generando bases de datos ahora ordenados.


:::

::: {.column width="50%"}

2. No hay forma de encontrar a la persona que recolectó/ingresó los datos

- Utiliza algunos paquetes avanzados de limpieza de datos orientados para este tipo particular de complicaciones.

- {unpivotr}
- {tidyxl}
- {unheadr}

- Aprende de un libro electrónico gratuito, [Estrategias de Manipulación de Hojas de Cálculo](https://nacnudus.github.io/spreadsheet-munging-strategies/)

:::
:::

